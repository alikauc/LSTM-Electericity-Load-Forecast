{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather and Load Data Preprocessing Pipeline for Calgary Electric Load Forecasting\n",
    "\n",
    "**Author:** Ali Karimi  \n",
    "**Purpose:** Process raw weather and electrical load data for Calgary (2011-2024) to create a clean, merged dataset for time series forecasting  \n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Weather Data Processing**: Parse ISD format, validate readings, handle missing data\n",
    "2. **Load Data Processing**: Process 4 separate load datasets across different time periods  \n",
    "3. **Data Integration**: Merge weather and load data with proper time alignment\n",
    "4. **Feature Engineering**: Add time-based features for forecasting models\n",
    "5. **Final Dataset**: Export clean, analysis-ready dataset\n",
    "\n",
    "## Data Sources:\n",
    "- **Weather**: ISD format meteorological data from multiple Calgary-area stations\n",
    "- **Load**: Calgary electrical load data from 4 separate CSV files covering 2011-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Starting weather and load data preprocessing pipeline...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Weather Data Processing\n",
    "\n",
    "Processing raw weather data from ISD (Integrated Surface Database) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw weather data from ISD (Integrated Surface Database) format\n",
    "weather_raw = pd.read_csv(\"load_data/weather_raw.csv\", low_memory=False)\n",
    "\n",
    "# Convert date strings to datetime objects for proper time series handling\n",
    "weather_raw[\"DATE\"] = pd.to_datetime(weather_raw[\"DATE\"])\n",
    "\n",
    "# Display sample of raw data to understand the ISD format structure\n",
    "weather_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The timestamps in raw data are in UTC time zone and need conversion to local time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round timestamps to the nearest hour for consistent merging with load data\n",
    "# This ensures all data points align to hourly boundaries (e.g., 14:23 → 14:00)\n",
    "weather_raw[\"DATE\"] = weather_raw[\"DATE\"].dt.round(\"H\")\n",
    "\n",
    "# Convert from UTC to Mountain Time (Calgary's timezone)\n",
    "# Step 1: Localize to UTC, Step 2: Convert to Denver timezone, Step 3: Remove timezone info\n",
    "weather_raw[\"DATE\"] = pd.to_datetime(weather_raw[\"DATE\"]).dt.tz_localize(\"UTC\").dt.tz_convert(\"America/Denver\").dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse TMP and WND into numerical values\n",
    "\n",
    "Convert ISD format strings to numerical values in degree Celsius and meter/sec according to ISD format documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_temp(temp_str):\n",
    "    \"\"\"\n",
    "    Parse ISD format temperature string to Celsius.\n",
    "    \n",
    "    ISD temperature format: [sign][degrees][decimal],quality_code\n",
    "    Example: '-0094,1' represents -9.4°C\n",
    "    \n",
    "    Args:\n",
    "        temp_str (str): Temperature string in ISD format\n",
    "        \n",
    "    Returns:\n",
    "        float: Temperature in Celsius\n",
    "    \"\"\"\n",
    "    temp_raw = temp_str.split(',')[0]  # Remove quality code after comma\n",
    "    sign = -1 if temp_raw[0] == '-' else 1  # Extract sign from first character\n",
    "    # Parse main digits (positions 1-3) and decimal digit (position 4)\n",
    "    value = int(temp_raw[1:4]) + int(temp_raw[4])/10\n",
    "    return sign*value\n",
    "\n",
    "# Apply temperature parsing function to create clean numerical column\n",
    "weather_raw['Temp_C'] = weather_raw['TMP'].apply(parse_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wnd(wnd_str):\n",
    "    \"\"\"\n",
    "    Parse ISD format wind speed string to meters per second.\n",
    "    \n",
    "    ISD wind format: direction,dir_quality,type,speed,speed_quality\n",
    "    Example: '320,1,N,0036,1' represents 3.6 m/s wind speed\n",
    "    \n",
    "    Args:\n",
    "        wnd_str (str): Wind string in ISD format\n",
    "        \n",
    "    Returns:\n",
    "        float: Wind speed in m/s, or 999 if invalid/missing\n",
    "    \"\"\"\n",
    "    parts = wnd_str.split(',')\n",
    "    if len(parts) != 5:\n",
    "        return 999  # Return error flag for invalid format\n",
    "    \n",
    "    direction, quality_dir, type_code, speed, quality_speed = parts\n",
    "    \n",
    "    # Validate that speed is numeric\n",
    "    try:\n",
    "        speed = int(speed)  \n",
    "    except ValueError:\n",
    "        return 999  # Return error flag for non-numeric speed\n",
    "\n",
    "    # Quality codes 2, 3, 6, 7 indicate erroneous values in ISD format\n",
    "    if quality_dir in {'2', '3', '6', '7'} or quality_speed in {'2', '3', '6', '7'}:\n",
    "        return 999\n",
    "    \n",
    "    # Speed code 9999 indicates missing data in ISD format\n",
    "    if speed == 9999:\n",
    "        return 999\n",
    "    \n",
    "    # Type code '9' indicates missing data\n",
    "    if type_code == '9':\n",
    "        return 999\n",
    "\n",
    "    # Convert to meters per second (ISD stores wind speed in 0.1 m/s units)\n",
    "    return speed / 10\n",
    "\n",
    "# Apply wind parsing function to create clean numerical column\n",
    "weather_raw['Wind_mps'] = weather_raw['WND'].apply(parse_wnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation: Flag Erroneous Temperature Readings\n",
    "\n",
    "Apply Calgary-specific climate validation rules to identify unrealistic temperature readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary month column for seasonal temperature validation\n",
    "weather_raw[\"Month\"] = pd.to_datetime(weather_raw[\"DATE\"]).dt.month\n",
    "\n",
    "def check_temp_valid(row):\n",
    "    \"\"\"\n",
    "    Validate temperature readings based on Calgary's seasonal climate patterns.\n",
    "    \n",
    "    Calgary climate context:\n",
    "    - Winter: Can reach -40°C, but rarely exceeds 15°C \n",
    "    - Spring/Fall: Moderate temperatures, rarely above 25°C\n",
    "    - Absolute maximum: 38°C (record high for Calgary region)\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): DataFrame row containing Temp_C and Month\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if temperature is within reasonable seasonal bounds\n",
    "    \"\"\"\n",
    "    temp = row[\"Temp_C\"]\n",
    "    month = row[\"Month\"]\n",
    "\n",
    "    # Apply seasonal temperature bounds to detect sensor errors\n",
    "    # Winter months (Dec, Jan, Feb): High temperatures indicate heating system errors\n",
    "    if (month in [12, 1, 2] and temp > 15.0) or \\\n",
    "       (month in [11, 3] and temp > 25.0) or \\\n",
    "       (temp > 38.0):  # Absolute maximum for Calgary region\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Apply temperature validation and create validity flag column\n",
    "weather_raw[\"Temp_valid\"] = weather_raw.apply(check_temp_valid, axis=1)\n",
    "\n",
    "# Remove temporary month column to keep dataset clean\n",
    "weather_raw.drop(columns=[\"Month\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation: Flag Erroneous Wind Speed Readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wind_valid(row):\n",
    "    \"\"\"\n",
    "    Validate wind speed readings by checking for error codes.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): DataFrame row containing Wind_mps\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if wind speed is valid (not error code 999)\n",
    "    \"\"\"\n",
    "    wind = row['Wind_mps']\n",
    "    # 999 is our designated error/missing flag from parsing function\n",
    "    if wind == 999:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "# Apply wind speed validation and create validity flag column\n",
    "weather_raw[\"Wind_valid\"] = weather_raw.apply(check_wind_valid, axis=1)\n",
    "\n",
    "# Display sample of processed data with validation flags\n",
    "weather_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Valid Data by Time\n",
    "\n",
    "Filter valid readings and aggregate multiple station reports into hourly averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only valid temperature and wind readings with their timestamps\n",
    "valid_temp = weather_raw[weather_raw[\"Temp_valid\"]][[\"DATE\", \"Temp_C\"]]\n",
    "valid_wind = weather_raw[weather_raw[\"Wind_valid\"]][[\"DATE\", \"Wind_mps\"]]\n",
    "\n",
    "# Aggregate multiple readings per hour by taking the mean\n",
    "# (Multiple weather stations may report for the same hour)\n",
    "temp_avg = valid_temp.groupby(\"DATE\", as_index=False).agg({\"Temp_C\": \"mean\"})\n",
    "wind_avg = valid_wind.groupby(\"DATE\", as_index=False).agg({\"Wind_mps\": \"mean\"})\n",
    "\n",
    "# Merge temperature and wind data on timestamp using outer join\n",
    "# This preserves records where only one measurement type is available\n",
    "weather_aggregated = pd.merge(temp_avg, wind_avg, on=\"DATE\", how=\"outer\")\n",
    "\n",
    "# Round to reasonable precision for cleaner dataset (1 decimal place)\n",
    "weather_aggregated[\"Temp_C\"] = weather_aggregated[\"Temp_C\"].round(1)\n",
    "weather_aggregated[\"Wind_mps\"] = weather_aggregated[\"Wind_mps\"].round(1)\n",
    "\n",
    "weather_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for and Handle Missing Data\n",
    "\n",
    "**Strategy:**\n",
    "- For short missing periods (<24 hr): Fill by linear interpolation\n",
    "- For long missing periods (>= 24 hr): Find secondary data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive time range covering the entire dataset period\n",
    "# Full time range: from first record to last record with hourly frequency\n",
    "full_range = pd.date_range(start=weather_aggregated['DATE'].min(), \n",
    "                          end=weather_aggregated['DATE'].max(), freq='H')\n",
    "\n",
    "# Identify missing time periods by comparing full range with actual data\n",
    "missing_times = full_range.difference(weather_aggregated['DATE'])\n",
    "\n",
    "# Identify duplicate timestamps (should be rare after aggregation)\n",
    "duplicated_times = weather_aggregated['DATE'][weather_aggregated['DATE'].duplicated(keep=False)]\n",
    "\n",
    "print(\"Missing times:\")\n",
    "print(missing_times)\n",
    "\n",
    "print(\"\\nDuplicated times:\")\n",
    "print(duplicated_times.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze partial missing data where one variable is missing but not the other\n",
    "missing_wind = weather_aggregated[weather_aggregated['Wind_mps'].isna()]\n",
    "missing_temp = weather_aggregated[weather_aggregated['Temp_C'].isna()]\n",
    "\n",
    "print(\"Missing Wind:\")\n",
    "print(missing_wind)\n",
    "print(\"\\nMissing Temperature:\")\n",
    "print(missing_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete time series by merging with full hourly range\n",
    "# This adds NaN values for all missing timestamps\n",
    "weather_aggregated['DATE'] = pd.to_datetime(weather_aggregated['DATE'])\n",
    "weather_complete = pd.DataFrame({'DATE': full_range}).merge(weather_aggregated, on='DATE', how='left')\n",
    "\n",
    "# Save intermediate result for backup\n",
    "weather_complete.to_csv(\"load_data/weather_processed2_merged.csv\")\n",
    "weather_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Missing Data Patterns\n",
    "\n",
    "Identify long missing periods that require external data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted chronologically for gap analysis\n",
    "weather_complete['DATE'] = pd.to_datetime(weather_complete['DATE'])\n",
    "weather_complete = weather_complete.sort_values(by='DATE')\n",
    " \n",
    "def find_long_missing_periods(df, column, min_gap=24):\n",
    
