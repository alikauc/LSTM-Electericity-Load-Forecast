{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ff0d55-71e2-46b4-8735-737c2f16fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Load pandas for data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72738f5-c71a-4a13-9385-53e76c2978ec",
   "metadata": {},
   "source": [
    "# Data cleaning process for weather-related data\n",
    "# This section prepares meteorological data for use with an LSTM model for electricity load forecasting in Calgary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "129ca046-68ab-4055-b50e-df1b3f01f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_raw = pd.read_csv(\"load_data/weather_raw.csv\", low_memory=False)  # Load raw weather data\n",
    "weather_raw[\"DATE\"] = pd.to_datetime(weather_raw[\"DATE\"])  # Parse date column to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f6ad431-078b-4219-8954-c7615aaa7962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       /* ... */
      ],
      "text/plain": [
       /* ... */
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_raw.head()  # Preview first rows for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc45fd-6841-447e-b77e-294d267d6f97",
   "metadata": {},
   "source": [
    "Note: The timestamps in raw data are in UTC time zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c2443b-1dc4-4631-82b0-21ab61873d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize timestamps to the nearest hour for consistency when merging datasets\n",
    "weather_raw[\"DATE\"] = weather_raw[\"DATE\"].dt.round(\"H\")\n",
    "# Convert timestamps from UTC to local (Mountain Time) for Calgary\n",
    "weather_raw[\"DATE\"] = pd.to_datetime(weather_raw[\"DATE\"]).dt.tz_localize(\"UTC\").dt.tz_convert(\"America/Denver\").dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f6b5f-9489-4d9d-a8e2-dbde4db0507c",
   "metadata": {},
   "source": [
    "### Parse TMP and WND into numerical values in degree Celcius and meter/sec, according to ISD format document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eab4685-15a9-428e-b060-d56ac37c245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temperature values in Celsius from ISD string format\n",
    "def parse_temp(temp_str):\n",
    "    temp_raw = temp_str.split(',')[0]  # Get the numeric part before the comma\n",
    "    sign = -1 if temp_raw[0] == '-' else 1  # Determine sign\n",
    "    value = int(temp_raw[1:4]) + int(temp_raw[4])/10  # Parse value\n",
    "    return sign*value\n",
    "weather_raw['Temp_C'] = weather_raw['TMP'].apply(parse_temp)  # Apply to all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b9bb68-f240-439e-90b2-fcada8a798a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract wind speed in m/s from ISD string format\n",
    "def parse_wnd(wnd_str):\n",
    "    parts = wnd_str.split(',')\n",
    "    if len(parts) != 5:\n",
    "        return 999  # Invalid format, flag as missing\n",
    "    \n",
    "    direction, quality_dir, type_code, speed, quality_speed = parts\n",
    "    try:\n",
    "        speed = int(speed)  # Parse speed value\n",
    "    except ValueError:\n",
    "        return 999\n",
    "\n",
    "    # Quality checks (based on ISD documentation): certain codes indicate erroneous or missing values\n",
    "    if quality_dir in {'2', '3', '6', '7'} or quality_speed in {'2', '3', '6', '7'}:\n",
    "        return 999\n",
    "    if speed == 9999:\n",
    "        return 999\n",
    "    if type_code == '9':\n",
    "        return 999\n",
    "\n",
    "    # Convert to meters per second\n",
    "    return speed / 10\n",
    "weather_raw['Wind_mps'] = weather_raw['WND'].apply(parse_wnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71b7f97b-9d2d-408d-8b5f-95f94f0a74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify erroneous temperature values based on seasonal expectations\n",
    "# Add a helper column with month for seasonal filtering\n",
    "weather_raw[\"Month\"] = pd.to_datetime(weather_raw[\"DATE\"]).dt.month\n",
    "\n",
    "def check_temp_valid(row):\n",
    "    temp = row[\"Temp_C\"]\n",
    "    month = row[\"Month\"]\n",
    "    # Flag unexpectedly high temperatures for winter and abnormally high temperatures overall as invalid\n",
    "    if (month in [12, 1, 2] and temp > 15.0) or \\\n",
    "       (month in [11, 3] and temp > 25.0) or \\\n",
    "       (temp > 38.0):\n",
    "        return False\n",
    "    return True\n",
    "weather_raw[\"Temp_valid\"] = weather_raw.apply(check_temp_valid, axis=1)\n",
    "weather_raw.drop(columns=[\"Month\"], inplace=True)\n",
    "\n",
    "# Flag erroneous wind speed values (flag value 999 from parsing)\n",
    "def check_wind_valid(row):\n",
    "    wind = row['Wind_mps']\n",
    "    if wind == 999:\n",
    "        return False\n",
    "    return True\n",
    "weather_raw[\"Wind_valid\"] = weather_raw.apply(check_wind_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc26581-ced3-4f06-8381-05a0017d00e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       /* ... */
      ],
      "text/plain": [
       /* ... */
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_raw.head()  # Check that flag columns and parsed data look correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9174ae93-527e-4566-9819-2f6c59b611bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to valid temperature and wind records for aggregation\n",
    "valid_temp = weather_raw[weather_raw[\"Temp_valid\"]][[\"DATE\", \"Temp_C\"]]\n",
    "valid_wind = weather_raw[weather_raw[\"Wind_valid\"]][[\"DATE\", \"Wind_mps\"]]\n",
    "\n",
    "# Aggregate by hour (if multiple measurements per hour, take the mean)\n",
    "temp_avg = valid_temp.groupby(\"DATE\", as_index=False).agg({\"Temp_C\": \"mean\"})\n",
    "wind_avg = valid_wind.groupby(\"DATE\", as_index=False).agg({\"Wind_mps\": \"mean\"})\n",
    "\n",
    "# Merge temperature and wind data on timestamp\n",
    "weather_aggregated = pd.merge(temp_avg, wind_avg, on=\"DATE\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7808710-b231-45a3-87a7-9ef4035ef101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round values to one decimal for consistency and model input\n",
    "weather_aggregated[\"Temp_C\"] = weather_aggregated[\"Temp_C\"].round(1)\n",
    "weather_aggregated[\"Wind_mps\"] = weather_aggregated[\"Wind_mps\"].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4bb9318-8706-4bc5-9b7d-4da4a8c6ab87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       /* ... */
      ],
      "text/plain": [
       /* ... */
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_aggregated.head()  # Preview cleaned, aggregated weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e52878-aa7a-4504-bcd6-fe848f4fe8e7",
   "metadata": {},
   "source": [
    "### Check for and handle missing data\n",
    "##### For short missing periods (<24 hr), fill by linear interpolation\n",
    "##### For long missing periods (>= 24 hr), find secondary data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ca5b90c-e5b1-456c-ac08-2b57296d4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      /* ... */
     ]
    }
   ],
   "source": [
    "# Generate the expected complete hourly time series for merging and gap-checking\n",
    "full_range = pd.date_range(start=weather_aggregated['DATE'].min(), end=weather_aggregated['DATE'].max(), freq='H')\n",
    "\n",
    "# Find missing timestamps (hours with no valid record)\n",
    "missing_times = full_range.difference(weather_aggregated['DATE'])\n",
    "\n",
    "# Find duplicated timestamps (should be rare after aggregation)\n",
    "duplicated_times = weather_aggregated['DATE'][weather_aggregated['DATE'].duplicated(keep=False)]\n",
    "\n",
    "print(\"Missing times:\")\n",
    "print(missing_times)\n",
    "\n",
    "print(\"\\nDuplicated times:\")\n",
    "print(duplicated_times.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1369a70f-062d-4c9a-9841-7f703b35fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      /* ... */
     ]
    }
   ],
   "source": [
    "# Check for records missing either wind or temperature\n",
    "missing_wind = weather_aggregated[weather_aggregated['Wind_mps'].isna()]\n",
    "missing_temp = weather_aggregated[weather_aggregated['Temp_C'].isna()]\n",
    "\n",
    "print(\"Missing Wind:\")\n",
    "print(missing_wind)\n",
    "print(\"\\nMissing Temperature:\")\n",
    "print(missing_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7b85514-612b-4f65-8358-199b526800a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       /* ... */
      ],
      "text/plain": [
       /* ... */
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge aggregated weather data with complete hourly time index, so all expected timestamps are present\n",
    "weather_aggregated['DATE'] = pd.to_datetime(weather_aggregated['DATE'])\n",
    "weather_complete = pd.DataFrame({'DATE': full_range}).merge(weather_aggregated, on='DATE', how='left')\n",
    "weather_complete.to_csv(\"load_data/weather_processed2_merged.csv\")\n",
    "weather_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42198d83-a137-4f0c-b131-dc3842e0e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure timestamps are sorted and consistent\n",
    "weather_complete['DATE'] = pd.to_datetime(weather_complete['DATE'])\n",
    "weather_complete = weather_complete.sort_values(by='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6170eb-bae3-490c-9fd2-fafb040dcc50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52fc6130-4ff8-4eec-9994-824cf0ed4b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       /* ... */
      ],
      "text/plain": [
       /* ... */
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_long_missing_periods(df, column, min_gap=24):\n",
    "    \"\"\"\n",
    "    Find consecutive missing periods longer than min_gap hours in a column.\n",
    "    Returns those periods for further handling.\n",
    "    \"\"\"\n",
    "    missing = df[column].isna()  # Boolean mask for missing values\n",
    "    missing_groups = (missing != missing.shift()).cumsum()  # Assign group for consecutive gaps\n",
    "    gap_sizes = missing.groupby(missing_groups).transform('sum')  # Size of each gap\n",
    "    long_missing = (missing & (gap_sizes >= min_gap))  # Filter gaps longer than min_gap\n",
    "    return df.loc[long_missing, ['DATE', column]]  # Return affected rows\n",
    "\n",
    "# Find periods of missing data for temperature and wind longer than 24 hours\n",
    "long_missing_temp = find_long_missing_periods(weather_complete, 'Temp_C', min_gap=24)\n",
    "long_missing_wind = find_long_missing_periods(weather_complete, 'Wind_mps', min_gap=24)\n",
    "\n",
    "# Save gaps for manual inspection/filling\n",
    "long_missing_temp.to_csv(\"missing_temp.csv\", index=False)\n",
    "long_missing_wind.to_csv(\"missing_wind.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"missing_temp.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8192b3dd-8a8b-41c2-b7ab-6c44cdcf1b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      /* ... */
     ]
    }
   ],
   "source": [
    "# Identify start/end and length for each long missing temperature period\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values('DATE').reset_index(drop=True)\n",
    "# Calculate time gaps to identify consecutive periods\n",
    "df['Time_Diff'] = df['DATE'].diff().dt.total_seconds() / 3600\n",
    "group_id = 0\n",
    "group_ids = []\n",
    "for diff in df['Time_Diff'].fillna(float('inf')):\n",
    "    if diff == 1:\n",
    "        group_ids.append(group_id)\n",
    "    else:\n",
    "        group_id += 1\n",
    "        group_ids.append(group_id)\n",
    "df['Group_ID'] = group_ids\n",
    "# Filter only long (over 24 hour) gaps for reporting\n",
    "group_sizes = df.groupby('Group_ID').size()\n",
    "valid_groups = group_sizes[group_sizes > 24].index\n",
    "# Print summary of each missing period\n",
    "result = df[df['Group_ID'].isin(valid_groups)]\n",
    "grouped = result.groupby('Group_ID')['DATE'].agg(['min', 'max', 'count'])\n",
    "print(\"Long missing period of temperature\")\n",
    "print(grouped.rename(columns={'min': 'Start', 'max': 'End', 'count': 'Length'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eae04289-0ba5-4a54-af01-56dac1970fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      /* ... */
     ]
    }
   ],
   "source": [
    "# Repeat for wind speed gaps\n",
    "df_wind = pd.read_csv(\"missing_wind.csv\")\n",
    "df_wind['DATE'] = pd.to_datetime(df_wind['DATE'])\n",
    "df_wind = df_wind.sort_values('DATE').reset_index(drop=True)\n",
    "df_wind['Time_Diff'] = df_wind['DATE'].diff().dt.total_seconds() / 3600\n",
    "# Assign group IDs for consecutive missing periods\n",
    "group_id_wind = 0\n",
    "group_ids_wind = []\n",
    "for diff in df_wind['Time_Diff'].fillna(float('inf')):\n",
    "    if diff == 1:\n",
    "        group_ids_wind.append(group_id_wind)\n",
    "    else:\n",
    "        group_id_wind += 1\n",
    "        group_ids_wind.append(group_id_wind)\n",
    "df_wind['Group_ID'] = group_ids_wind\n",
    "# Find only long gaps (>24 hours)\n",
    "group_sizes = df_wind.groupby('Group_ID').size()\n",
    "valid_groups = group_sizes[group_sizes > 24].index\n",
    "# Print summary of each missing wind period\n",
    "result = df_wind[df_wind['Group_ID'].isin(valid_groups)]\n",
    "grouped = result.groupby('Group_ID')['DATE'].agg(['min', 'max', 'count'])\n",
    "print(\"Long missing period of wind\")\n",
    "print(grouped.rename(columns={'min': 'Start', 'max': 'End', 'count': 'Length'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e18d6c5-d8e2-4dd1-8ed3-fe180d81616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate short missing periods (<24 hours), leave long gaps for manual/secondary data filling\n",
    "def mask_long_gaps(series, max_gap=24):\n",
    "    \"\"\"Return mask for short missing periods (< max_gap hours) for interpolation\"\"\"\n",
    "    is_na = series.isna()\n",
    "    group = (~is_na).cumsum()\n",
    "    gap_sizes = is_na.groupby(group).transform('sum')\n",
    "    return (gap_sizes < max_gap)\n",
    "\n",
    "# Flag short gaps for filling\n",
    "mask_temp = mask_long_gaps(weather_complete['Temp_C'], max_gap=24)\n",
    "mask_wind = mask_long_gaps(weather_complete['Wind_mps'], max_gap=24)\n",
    "\n",
    "# Apply linear interpolation for short gaps only\n",
    "weather_complete.loc[mask_temp, 'Temp_C'] = weather_complete['Temp_C'].interpolate(method='linear')\n",
    "weather_complete.loc[mask_wind, 'Wind_mps'] = weather_complete['Wind_mps'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17775f14-2704-4c56-bebc-9655cc89d0e2",
   "metadata": {},
   "source": [
    "Long missing periods are filled with data from a secondary online climate database, Weather Spark (https://weatherspark.com).\n",
    "Now the weather-related data is complete and ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2def027d-c403-4108-b51b-9b6db5b88be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_complete.to_csv(\"load_data/weather_complete_.csv\", index=False)  # Save cleaned, complete weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25fa99-3891-40c9-894c-8a02c56b8754",
   "metadata": {},
   "source": [
    "# Data cleaning process for load data\n",
    "# The next section preprocesses electricity load data for use in LSTM model training.\n",
    "### Load 1 - 2011-01-01 - 2016-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d2c4421-974b-4d17-a4e7-470ff341df6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       /* ... */
      ],
      "text/plain": [
       /* ... */
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    /* ... */
   ]
  }
 ]
}
